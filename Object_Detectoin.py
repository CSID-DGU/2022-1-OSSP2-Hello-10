# -*- coding: utf-8 -*-
"""Detectron2_training_custom_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T9K9mH1TMNcyjIJUS72QuGv_sg8iOiMZ

# 1. DATASET 구성

다운로드  
[aihub_27_classes_label.csv](https://www.dropbox.com/s/mh3yeeu22h8spqb/aihub_27_classes_label.csv
)  
[aihub_13_classes_label.csv](https://www.dropbox.com/s/byecey0zebrn203/aihub_13_classes_label.csv
)

```
${DATASET_ROOT}
 `-- aihub_27_classes_label.csv
  -- aihub_13_classes_label.csv
  -- images`
     |-- 0617_01
     |   |-- 0617_01.xml
     |   |-- MP_SEL_000001.jpg
     |   |-- MP_SEL_000002.jpg
     |   |-- MP_SEL_000003.jpg
     |   |-- MP_SEL_000004.jpg
     |   |-- ...
     |-- 0617_02
     |   |-- 0617_02.xml
     |   |-- MP_SEL_000201.jpg
     |   |-- MP_SEL_000202.jpg
     |   |-- MP_SEL_000203.jpg
     |   |-- MP_SEL_000204.jpg
     |   |-- ...
     |-- 0617_04
     |   |-- 0617_03.xml
     |   |-- MP_SEL_000601.jpg
     |   |-- MP_SEL_000602.jpg
     |   |-- MP_SEL_000603.jpg
     |   |-- MP_SEL_000604.jpg
     |   |-- ...
```
"""

# for detectron2
import torchvision
import torch
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo
import matplotlib.pyplot as plt
import random
from detectron2.data import DatasetCatalog, MetadataCatalog
from google.colab import drive
from detectron2.structures import BoxMode
from detectron2.data import MetadataCatalog
from detectron2.utils.visualizer import Visualizer
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor
import xml.etree.ElementTree as elemTree
from glob import glob
import itertools
import json
import cv2
import numpy as np
import csv
from detectron2.utils.logger import setup_logger
import detectron2
import os
!pip install pyyaml == 5.1
!pip install torch == 1.9.0+cu102 torchvision == 0.10.0+cu102 - f https: // download.pytorch.org/whl/torch_stable.html
!pip install detectron2 - f https: // dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html

# to deal with xml files
!pip install xmltodict

# 기본 설정
# detectron2 logger 설정
setup_logger()

# 자주 사용하는 라이브러리 임폴트

# 자주 사용하는 detectron2 utils imoprt

print(torch.__version__)

# for accessing colab files

drive.mount('/content/drive')
root_path = '/content/drive/MyDrive/'  # change dir to your project folder

DATASET_ROOT = '/content/drive/MyDrive/OD'  # dataset Driectory

"""# 2. 레이블 파일 불러오기 """


def get_label_list(label_path):

    labels = []

    with open(label_path) as csvfile:
        readCSV = csv.reader(csvfile, delimiter=',')
        for row in readCSV:
            labels.append(row[0])
    return labels


label_path = os.path.join(DATASET_ROOT, "aihub_27_classes_label.csv")
labels = get_label_list(label_path)
print(labels)

"""# 3. get_crosswalk_dicts 함수 작성
Detectron2에 Dataset 등록을 위해 필요한 함수를 작성합니다.  
같은 방법으로 validation dataset을 구성하여 학습에 이용할 수 있습니다. 
"""


def get_crosswalk_dicts():

    label_path = os.path.join(DATASET_ROOT, "aihub_27_classes_label.csv")
    image_path = os.path.join(DATASET_ROOT, 'images')

    dirs = glob(os.path.join(image_path, '*'))
    xmls = glob(os.path.join(image_path, '*/*.xml'))

    labels = get_label_list(label_path)
    dataset_dicts = []
    # for xml in xmls:
    for sub_dir in dirs:

        xml_path = os.path.join(sub_dir, glob(
            os.path.join(sub_dir, "*.xml"))[0])
        images_path = glob(os.path.join(sub_dir, "*.jpg"))
        tree = elemTree.parse(xml_path)
        for image in tree.findall('./image'):

            jpg_name = os.path.join(sub_dir, image.attrib['name'])
            if not jpg_name in images_path:
                print("pass because no image -> {}".format(jpg_name))
                continue

            record = {}
            record["file_name"] = jpg_name
            record["height"] = int(image.attrib['height'])
            record["width"] = int(image.attrib['width'])

            objs = []
            for box in image.findall('./box'):
                obj = {
                    "bbox": [
                        float(box.attrib['xtl']),
                        float(box.attrib['ytl']),
                        float(box.attrib['xbr']),
                        float(box.attrib['ybr'])],
                    "bbox_mode": BoxMode.XYXY_ABS,
                    # category_id should be customized
                    "category_id": (labels.index(box.attrib['label']) if box.attrib['label'] in labels else 0),
                    "iscrowd": 0
                }
                objs.append(obj)
            record["annotations"] = objs
            dataset_dicts.append(record)
    return dataset_dicts


"""# 4. 데이터셋 등록   """

DatasetCatalog.register("crosswalk/train", get_crosswalk_dicts)
MetadataCatalog.get("crosswalk/train").set(thing_classes=labels)
crosswalk_metadata = MetadataCatalog.get("crosswalk/train")

# Commented out IPython magic to ensure Python compatibility.
# 잘 등록되었나 확인
# %matplotlib inline


def cv2_imshow(image):
    plt.figure(figsize=(20, 20))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.show()


dataset_dicts = get_crosswalk_dicts()
for d in random.sample(dataset_dicts, 3):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(
        img[:, :, ::-1], metadata=crosswalk_metadata, scale=0.5)
    vis = visualizer.draw_dataset_dict(d)
    cv2_imshow(vis.get_image()[:, :, ::-1])

"""# 5. RetinaNet 학습하기"""

# os.chdir("/home/visionnoob/git_project/detectron2")

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(
    "COCO-Detection/retinanet_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("crosswalk/train",)
cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
# 300 iterations seems good enough, but you can certainly train longer
cfg.SOLVER.MAX_ITER = 3
# faster, and good enough for this toy dataset
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 27  # only has one class (ballon)

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=True)
trainer.train()

cfg.MODEL.WEIGHTS = "/content/output/model_final.pth"  # model path
# set the testing threshold for this model
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
predictor = DefaultPredictor(cfg)

path = "/content/drive/MyDrive/OD/images/bbox/MP_SEL_B027452.jpg"

im = cv2.imread(path)
outputs = predictor(im)
v = Visualizer(
    im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])
